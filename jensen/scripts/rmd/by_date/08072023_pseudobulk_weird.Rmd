---
title: "PseudoBulk V2"
author: "Brian Gural"
date: "2023-08-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load libs, message=FALSE, echo = F, warning=FALSE, results= 'hide', cache=FALSE, include=T}
# List libraries
libs <- c("Seurat", "ggplot2", "patchwork", "SeuratDisk","reshape2", "tidyverse",
          "SCpubr","shiny", "ggrepel", "gridExtra", "scCustomize", "httr", 
          "scales", "dplyr", "DeconvoBuddies", "readr", "SingleCellExperiment",
          "SummarizedExperiment", "Biobase", "ggmagnify", "stringr", "MuSiC",
          "ggforce", "DirichletReg", "readxl", "viridis", "DESeq2") # list libraries here
# Require all of them
lapply(libs, require, character.only = T)

# Also load in-house functions
source("jensen/scripts/functions/decon_all.R")
```

```{r load data, cache = TRUE, echo=FALSE, message=F}
sn <- LoadH5Seurat("jensen/data/processed/single_cell/merged_datasets/07192023/07192023_1.h5seurat")
```
## R Markdown


```{r functions}

# Sum expression of each cell type cluster in the seurat
GetCellProfile <- function(seurat, cell.type){
  cell.ids  <- Idents(seurat)[which(Idents(seurat) == cell.type)] |>
    names() # Get the cell.ids that are the cell type of interest
  cell.type.profile <- rowSums(seurat@assays$RNA@counts[,cell.ids]) |>
    as.numeric()  # sum expression of cells with those ids
  assign(as.character(cell.type), cell.type.profile) # name the profile with the cell type
  return(get(as.character(cell.type)))
}


cell.types <- unique(Idents(sn))
# Make matrix of expression profiles 
# Each col should be a cell type
# Each row should be a gene
cell.expr.prof <- sapply(cell.types, function(x){GetCellProfile(sn, x)}, USE.NAMES = T)
colnames(cell.expr.prof) <- cell.types
row.names(cell.expr.prof) <- row.names(sn) 


# This defines the probability of which gene a single UMI will be, by cell type
# each cell will contain the probability of a random UMI from that cell type/column to be that gene/row
# Could be simultaneous with prior step
gene.probs <- prop.table(cell.expr.prof, 2) |>
  as.data.frame()

# Make function to take in a named list of proportions, then multiply by the ratio
# then multiply it all by umi target
# then add noise
# then round to integers

MakePseudoBulk <- function(ratios, profiles, umi_target, noise) {
  ratio.format <- as.vector(ratios)
  names(ratio.format) <- names(ratios)
  # Ensure ratios is a named list or named vector
  if (!is.list(ratio.format) && !is.vector(ratio.format)) {
    stop("ratios must be a named list or named vector")
  }
  if (!all(names(ratio.format) %in% names(profiles))) {
    stop("All names in ratios must be present as columns in profiles")
  }

  # Modify columns by multiplying with ratios and adding noise
  profiles.use <- profiles |>
    select(all_of(names(ratio.format))) |>
    mutate(across(all_of(names(ratio.format)), 
                  ~ jitter(.x * ratio.format[[as.character(cur_column())]], factor = noise)))
    #rnorm(n()) adds Gaussian noise to each column. Generates random numbers from a normal distribution with a standard deviation of noise.
  profiles.use[profiles.use < 0 ] <- 0
  # Compute mean of all columns
  mean_column <- profiles.use |>
    rowMeans()

  # Normalize the result to sum to 1
  mean_column_norm <- mean_column / sum(mean_column)
  counts <- mean_column_norm * umi_target
  counts <- counts |>
    round() |>
    as.integer()
  
  names(counts) <- row.names(profiles)
  
  return(counts)
}
```

```{r make pb ratios}
simulate_ratios <- function(cell_types, step_range) {
  
  # Define the range for proportions
  proportions <- rep(seq(1/length(cell_types), 0.4, by = step_range), each = 5)
  
  # Create combinations of cell.types and proportions
  combinations <- expand.grid(cell = cell_types, prop = proportions, stringsAsFactors = FALSE)
  
  # Function to generate a single ratio list for a given cell and prop
  generate_ratio <- function(cell, prop, all_types) {
    n <- length(all_types)
    remaining_prop <- (1 - prop) / (n - 1)
    
    # Create the named list
    ratio_list <- setNames(rep(remaining_prop, n), all_types)
    ratio_list[cell] <- prop
    
    return(ratio_list)
  }
  
  # Apply the function to each combination
  ratio_lists <- apply(combinations, 1, function(row) {
    generate_ratio(row['cell'], as.numeric(row['prop']), cell_types)
  })
  
  # Naming the lists
  names(ratio_lists) <- paste(combinations$cell, sprintf("%.2f", combinations$prop), sep = "_")
  return(ratio_lists)
}

# Test
cell.ratios <- simulate_ratios(cell.types, step_range = 0.02) |>
               t()
rownames(cell.ratios) <- paste0("mix_", seq(1:nrow(cell.ratios)))

```


```{r make pseudobulk}
# Function to make a list of cell type ratios

# take each row of cell.ratios and put it into MakePseudoBulk 
pb.comps <- sapply(1:nrow(cell.ratios), function(x){MakePseudoBulk(cell.ratios[x,], gene.probs, 1000000, 0.7)})
colnames(pb.comps) <- rownames(cell.ratios)


# Make replicates of even ratio pseudobulk
cell.ratios.ref <- cell.ratios[1:5,]
rownames(cell.ratios.ref) <- paste0("ref_", rownames(cell.ratios)[1:5])
pb.refs <- sapply(1:nrow(cell.ratios.ref), function(x){MakePseudoBulk(cell.ratios.ref[x,], gene.probs, 1000000, 0.7)})
colnames(pb.refs) <- rownames(cell.ratios.ref)

# Merge datasets


cell.ratios.ref <- as.data.frame(cell.ratios.ref)
cell.ratios.ref$pct.diff <- "ref"
cell.ratios.ref$major.type <- NA


cell.ratios <- as.data.frame(cell.ratios)
cell.ratios$pct.diff <- rep(seq(0, 20,2), each = 25)
cell.ratios$major.type <- c(rep(NA, 25), rep(as.character(cell.types), times = 10*5))


## repeat above code but with equal proportions
## join in matrix
## make design matrix with compositions
## Run DESeq2
## Get rate of DE 
## Repeat DESeq2 with raw compositions, PCA, and CLR

```

```{r deseq prep}

cur.ratios <- cell.ratios |>
              subset(pct.diff == 10 & major.type == "fibroblasts")
cur.pb <- pb.comps |> 
          as.data.frame() |> 
          select(rownames(cur.ratios))

merge.ratios <- rbind(cell.ratios.ref, cur.ratios)
merge.pb <- cbind(pb.refs, cur.pb)
# start with 1 pt diff
# Prepare sample information
sample_info <- data.frame(
  row.names = colnames(merge.pb),
  group =  as.factor(merge.ratios$pct.diff) 
)


# Create a DESeqDataSet
dds <- DESeqDataSetFromMatrix(
  countData = merge.pb,
  colData = sample_info,
  design = ~ group  # include interaction term
)

# Run the DESeq pipeline
dds <- DESeq(dds)

resultsNames(dds)

# Run the differential expression analysis
res <- results(dds, name = resultsNames(dds)[2])
hist(res$padj, breaks = 20)
sig.genes <- res |>
  subset(padj < 0.05) |>
  nrow()
```

```{r apply for deseq}

all_combinations <- expand.grid(pct.diff = unique(cell.ratios$pct.diff)[unique(cell.ratios$pct.diff)!= 0],
                                major.type = unique(cell.ratios$major.type)[!is.na(unique(cell.ratios$major.type))])

# The function to be applied for each combination
perform_analysis <- function(pct_diff, major_type) {
  cur.ratios <- cell.ratios %>%
                subset(pct.diff == pct_diff & major.type == as.character(major_type))
  
  cur.pb <- pb.comps %>% 
            as.data.frame() %>% 
            select(rownames(cur.ratios))
  
  merge.ratios <- rbind(cell.ratios.ref, cur.ratios)
  merge.pb <- cbind(pb.refs, cur.pb)

  sample_info <- data.frame(
    row.names = colnames(merge.pb),
    group = as.factor(merge.ratios$pct.diff)
  )

  dds <- DESeqDataSetFromMatrix(
    countData = merge.pb,
    colData = sample_info,
    design = ~ group
  )

  dds <- DESeq(dds)
  res <- results(dds, name = resultsNames(dds)[2])
  
  sig.genes <- res %>%
               subset(padj < 0.01) %>%
               nrow()
  
  return(sig.genes)
}

results <- mapply(perform_analysis, 
                 pct_diff = all_combinations$pct.diff, 
                 major_type = all_combinations$major.type)

names(results) <- apply(all_combinations, 1, paste, collapse = "-")


```


```{r prior code}
names(list.example) <- cell.types
# Function to get all permutations of cell types. Output is fed to MakePseudoBulk
GetAllPermutations <- function(out.length, cell.types){
  perms <- gtools::permutations(n = length(cell.types), r = out.length, v = as.vector(cell.types)) |>
    t()
  return(lapply(seq_len(ncol(perms)), function(i) perms[,i]))
}

# make nested list of all possible cell type permutations
# covers each number of possible cell types
all.perms <- lapply( 1:length(cell.types), function(x) GetAllPermutations(x, cell.types))

# Sample 40 from each super group (super group is the term I'm using for # of cell types included)
even.perms <- lapply( all.perms, function(x) sample(x, 40, T))

# Set up socket cluster and populate it with things we need from our environment
library(parallel) 
cl <- makeCluster(4) # Don't rely on DetectCores(), it doesn't understand that we are only partitioned some of the cores for longleaf

# Bring libraries and obj/functions into cluster
clusterEvalQ(cl, c(lapply(libs, require, character.only = T)))
clusterExport(cl, c("SampleByIndex", "libs", "GetAllPermutations", "MakePseudoBulk","cell.types", "gene.probs", "umi.target", "even.perms"), 
              envir=environment())

# Splits the input by super group for parallelizing
# Then, within the super group, iterates through the lists of cell combinations
# Looks like MakePseudoBulk(... cells.include = c("cell.type.1", "cell.type.2"..."cell.type.n"))
# where 'n' changes between the super groups
start <- Sys.time()
cell.combos <- parLapply(cl, 1:length(cell.types), function(x) 
                lapply(even.perms[[x]], 
                       function(y) MakePseudoBulk(cell.profiles = gene.probs, 
                                                    umi = umi.target,
                                                    cells.include = y)))
time.par <- start - Sys.time()

stopCluster(cl)

# I hate this, but I can't figure out simpler way to compress the nested list into a df
combos.test <- enframe(cell.combos) |> 
  unnest(value) |> 
  unnest_wider(value, names_repair = "unique") |>
  t() |>
  as.data.frame()


# Use rle to calculate the lengths and values of runs
r <- rle(as.character(combos.test[1,]))

# Generate the sequence of indices for each run
indices <- unlist(lapply(r$lengths, seq_len))

# Combine the original values with the indices to get the desired output
result <- paste(as.character(combos.test[1,]), indices, sep = "_")
colnames(combos.test) <- result
combos.test <- combos.test[-1,]

#write.csv(combos.test, "gtex/data/processed/internal/pseudobulk/all_cells_n50.csv")
#save(even.perms, file = "gtex/data/processed/internal/pseudobulk/all_cells_n50_answers")
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
# set UMI target
umi.target <- median(colSums(bulk))

# Get cell types to include
cell.types <- unique(Idents(sn.all))


# Sum expression of each cell type cluster in the seurat
# Make matrix of expression profiles 
# Each col should be a cell type
# Each row should be a gene
cell.expr.prof <- sapply(cell.types, function(x){GetCellProfile(sn.all, x)}, USE.NAMES = T)
colnames(cell.expr.prof) <- cell.types
row.names(cell.expr.prof) <- row.names(sn.all)

# This defines the probability of which gene a single UMI will be, by cell type
# each cell will contain the probability of a random UMI from that cell type/column to be that gene/row
# Could be simultaneous with prior step
gene.probs <- prop.table(cell.expr.prof, 2) |>
  as.data.frame()

# Function to sample UMI indexes for making pseudobulk
# Assumes you want an equal ratio of cell types as is present in the profile
# Makes vector of gene probabilities, then samples n times (n = umi)
# makes a loooong vector of gene names, then summarizes them into counts of occurances with table()
# could be significantly faster, I think
SampleByIndex <- function(position, ratio, profile, umi){
  probs <- rowSums(profile) / ncol(profile) #Divide total UMI by # cell types to get UMI goal per cell type
  gene.vector <- sample(x = factor(1:nrow(profile)),
                        size = umi, 
                        prob = unlist(probs),
                        replace = T) |>
    table() |>
    as.list()
  names(gene.vector) <- rownames(profile)
  return(gene.vector)
}

# make nested list of all possible cell type permutations
# covers each number of possible cell types
all.perms <- lapply( 1:length(cell.types), function(x) GetAllPermutations(x, cell.types))

# Sample 40 from each super group (super group is the term I'm using for # of cell types included)
even.perms <- lapply( all.perms, function(x) sample(x, 40, T))


cell.combos <- lapply(cl, 1:length(cell.types), function(x) 
                lapply(even.perms[[x]], 
                       function(y) MakePseudoBulk(cell.profiles = gene.probs, 
                                                    umi = umi.target,
                                                    cells.include = y)))


# I hate this, but I can't figure out simpler way to compress the nested list into a df
combos.test <- enframe(cell.combos) |> 
  unnest(value) |> 
  unnest_wider(value, names_repair = "unique") |>
  t() |>
  as.data.frame()


# Use rle to calculate the lengths and values of runs
r <- rle(as.character(combos.test[1,]))

# Generate the sequence of indices for each run
indices <- unlist(lapply(r$lengths, seq_len))

# Combine the original values with the indices to get the desired output
result <- paste(as.character(combos.test[1,]), indices, sep = "_")
colnames(combos.test) <- result
combos.test <- combos.test[-1,]

#write.csv(combos.test, "gtex/data/processed/internal/pseudobulk/all_cells_n50.csv")
#save(even.perms, file = "gtex/data/processed/internal/pseudobulk/all_cells_n50_answers")

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
