Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 12
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	salmon_decoy
	1

[Mon Mar 11 11:06:06 2024]
rule salmon_decoy:
    input: data/raw/anno/gencode.vM34.transcripts.fa.gz
    output: data/raw/anno/decoy.txt
    jobid: 0

cut: invalid option -- 'i'
Try 'cut --help' for more information.
[Mon Mar 11 11:06:06 2024]
Error in rule salmon_decoy:
    jobid: 0
    output: data/raw/anno/decoy.txt
    shell:
        grep '^>' <(gunzip -c data/raw/anno/gencode.vM34.transcripts.fa.gz) | cut -d ' ' -f 1 > data/raw/anno/decoy.txt \ sed -i.bak -e 's/>//g' data/raw/anno/decoy.txt
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job salmon_decoy since they might be corrupted:
data/raw/anno/decoy.txt
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
