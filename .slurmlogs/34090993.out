Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 12
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=8000, disk_mb=1000
Select jobs to execute...

[Tue Mar 19 12:39:03 2024]
rule ambient_doublets:
    input: data/processed/single_cell/unprocessed/b6_1.h5seurat
    output: data/processed/single_cell/no_doublets/b6_1_no_doublets.h5seurat
    jobid: 0
    reason: Forced execution
    wildcards: sn_sample=b6_1
    resources: mem_mb=8000, disk_mb=1000, tmpdir=/tmp

Error in contrib.url(repos, type) : 
  trying to use CRAN without setting a mirror
Calls: <Anonymous> -> download_version_url -> contrib.url
Execution halted
[Tue Mar 19 12:39:03 2024]
Error in rule ambient_doublets:
    jobid: 0
    output: data/processed/single_cell/no_doublets/b6_1_no_doublets.h5seurat
    shell:
        Rscript scripts/2_ambient_doublets.R b6_1
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
