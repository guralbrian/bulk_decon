Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 12
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=1000, disk_mb=1000
Select jobs to execute...

[Mon Mar 18 16:20:38 2024]
rule clean_bulk:
    input: data/processed/bulk/all_bulk_gene.csv
    output: data/processed/bulk/all_counts.csv, data/processed/bulk/pheno_table.csv
    jobid: 0
    reason: Forced execution
    resources: mem_mb=1000, disk_mb=1000, tmpdir=/tmp

Loading required package: tidyverse
── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.4.4     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
Loading required package: reshape2

Attaching package: ‘reshape2’

The following object is masked from ‘package:tidyr’:

    smiths

Loading required package: makeunique
[[1]]
[1] TRUE

[[2]]
[1] TRUE

[[3]]
[1] TRUE

[Mon Mar 18 16:20:50 2024]
Finished job 0.
1 of 1 steps (100%) done
