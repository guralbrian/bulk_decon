---
title: "AHA BCVS GTEx Pseudobulk"
author: "Brian Gural"
date: "7/13/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Project Goals\
Estimate cellular composition in human hearts from bulk RNAseq



```{r load libs, message=FALSE, warning=FALSE, cache=F, include=F}
# load libraries
libs <- c("Seurat", "ggplot2", "DESeq2", "patchwork","SeuratDisk", "MuSiC", "reshape2",
          "tidyverse", "SingleCellExperiment","harmony", "SCpubr","shiny", 
          "AUCell", "viridis", "gplots", "scales", "ggrepel", "gridExtra", "scCustomize",
          "httr","readxl","matrixStats", "ggforce") # list libraries here
lapply(libs, require, character.only = T)
source("gtex/scripts/functions/decon_all.R")
```


## Analysis\

```{r load data, message=FALSE, warning=FALSE, cache=TRUE, include=TRUE}
# bulk
bulk <- read.csv("gtex/data/processed/internal/gtex_lv_counts_summed.csv", check.names = F, row.names = 2)[,-1]
stable_genes <- read.csv("gtex/data/processed/internal/gtex_stable_genes.csv", row.names = )
# Single cell of all datasets combined
sn.all <- LoadH5Seurat("gtex/data/processed/external/single_cell/sim_gtex.h5seurat")
sn.no.de <- subset(sn.all, features = rownames(sn.all)[rownames(sn.all) %in% stable_genes$x])

combos.test <- read.csv( "gtex/data/processed/internal/pseudobulk/all_cells_n50.csv", row.names = 1)
load("gtex/data/processed/internal/pseudobulk/all_cells_n50_answers")


colnames(combos.test) <- lapply(strsplit(colnames(combos.test), "X"), "[[", 2) |>
                          unlist()
```


```{r make pseudobulk data, message=FALSE, warning=FALSE, cache=TRUE, include=TRUE}
# set UMI goal

umi.target <- median(colSums(bulk))


# Get unique cell types
# limited to top 5 due to computational constraints
# and limited # of cells
cell.types <- unique(Idents(sn.all))


# Sum expression by cell type in the seurat
GetCellProfile <- function(seurat, cell.type){
  cell.ids  <- Idents(seurat)[which(Idents(seurat) == cell.type)] |>
                      names()
  cell.type.profile <- rowSums(seurat@assays$RNA@counts[,cell.ids]) |>
    as.numeric() 
  assign(as.character(cell.type), cell.type.profile)
  return(get(as.character(cell.type)))
}

cell.expr.prof <- sapply(cell.types, function(x){GetCellProfile(sn.all, x)}, USE.NAMES = T)
colnames(cell.expr.prof) <- cell.types
row.names(cell.expr.prof) <- row.names(sn.all)

# This defines the probability of which gene a single UMI will be, by cell type
gene.probs <- prop.table(cell.expr.prof, 2) |>
              as.data.frame()


# Function to sample UMI indexes for making pseudobulk
# Assumes you want an equal ratio of cell types as is present in the profile
# averages gene probabilities, then samples based on the average
# makes a loooong vector of gene names, then summarizes them into counts of occurances with table()
# could be significantly faster, I think
SampleByIndex <- function(position, ratio, profile, umi){
    probs <- rowSums(profile) / ncol(profile)
    gene.vector <- sample(x = factor(1:nrow(profile)),
                          size = umi, 
                          prob = unlist(probs),
                          replace = T) |>
                    table() |>
                    as.list()
    names(gene.vector) <- rownames(profile)
    return(gene.vector)
  }
# Function to create pseudobulk data for a given set of cell types
# ratios argument should be a list of ratios with appropriate names
# can be shorter than total # of cells
MakePseudoBulk <- function(cell.profiles, umi, cells.include = names(cell.profiles)) {
 cell.subset <- cell.profiles[colnames(cell.profiles) %in% cells.include]
 # Sample each cell type profile with appropriate UMI limit, store in nested list
 pb <- SampleByIndex(profile = cell.subset, umi = umi)  
 return(pb)
}

# Function to get permutations of cell types to use in MakePseudoBulk

GetAllPermutations <- function(out.length, cell.types){
  perms <- gtools::permutations(n = length(cell.types), r = out.length, v = as.vector(cell.types)) |>
           t()
  return(lapply(seq_len(ncol(perms)), function(i) perms[,i]))

}


# make nested list of cell type permutations 
all.perms <- lapply( 1:length(cell.types), function(x) GetAllPermutations(x, cell.types))

# Sample 10 from each super group (super groups are divided by # of cell types to be included)
even.perms <- lapply( all.perms, function(x) sample(x, 40, T))


# Set up socket cluster and populate it with things we need from our environment

library(parallel) 
cl <- makeCluster(4) # Don't rely on DetectCores(), it doesn't understand that we are only partitioned some of the cores for longleaf
clusterExport(cl, c("SampleByIndex", "libs", "GetAllPermutations", "MakePseudoBulk","cell.types", "gene.probs", "umi.target", "even.perms"), 
              envir=environment())
clusterEvalQ(cl, c(lapply(libs, require, character.only = T)))
clusterExport(cl, c("SampleByIndex", "libs", "GetAllPermutations", "MakePseudoBulk","cell.types", "gene.probs", "umi.target", "even.perms"), 
              envir=environment())

# Test linear vs parallel computing times
#start <- Sys.time()
#cell.combos <- lapply(1:length(cell.types), function(x)
#               lapply(even.perms[[x]], function(y) MakePseudoBulk(cell.profiles = gene.probs, 
#                                                            umi = umi.target,
#                                                            cells.include = y)))
#time.lin <- start - Sys.time()
#Time difference of -46.59644 secs for 8 combos

start <- Sys.time()
cell.combos <- parLapply(cl, 1:length(cell.types), function(x)
               lapply(even.perms[[x]], function(y) MakePseudoBulk(cell.profiles = gene.probs, 
                                                            umi = umi.target,
                                                            cells.include = y)))
time.par <- start - Sys.time()

stopCluster(cl)
#Time difference of -17.77441 secs for 8 combos

library(tidyr)
library(tibble)


combos.test <- enframe(cell.combos) |> 
  unnest(value) |> 
  unnest_wider(value, names_repair = "unique") |>
  t() |>
  as.data.frame()

# Your input vector

# Use rle to calculate the lengths and values of runs
r <- rle(as.character(combos.test[1,]))

# Generate the sequence of indices for each run
indices <- unlist(lapply(r$lengths, seq_len))

# Combine the original values with the indices to get the desired output
result <- paste(as.character(combos.test[1,]), indices, sep = "_")
colnames(combos.test) <- result
combos.test <- combos.test[-1,]

#write.csv(combos.test, "gtex/data/processed/internal/pseudobulk/all_cells_n50.csv")
#save(even.perms, file = "gtex/data/processed/internal/pseudobulk/all_cells_n50_answers")

```


```{r DeconvoBuddies Find markers, fig.width = 7, fig.height= 8, echo=FALSE, message=FALSE, warning=FALSE}
# find markers
library(DeconvoBuddies)
library(BisqueRNA)
GetMarkers <- function(seurat.obj, bulk.obj){ 
# Subset # of cells to speed up script
n_cells <- 15000
cells <- sample(colnames(seurat.obj), n_cells, replace = FALSE)

# Subset sn.labeled for genes common to bulk RNAseq and cells of interest
seurat <- seurat.obj |>
    subset(cells = cells, features = rownames(seurat.obj)[rownames(seurat.obj) %in% rownames(bulk.obj)])

# Function needs a SummarizedExperiment format
sn.sce <- as.SingleCellExperiment(seurat, assay = "RNA") |>
  as("SummarizedExperiment")

# add gene names, not sure why they broke
gene_names <- rownames(seurat@assays$RNA@counts)
rownames(sn.sce) <- gene_names

# Run marker selection pipeline from DeconvolBuddies
ratios <- get_mean_ratio2(sn.sce, cellType_col = "ident")
fc <- findMarkers_1vAll(sn.sce, cellType_col = "ident", mod = "~Participant.ID")
marker_stats <- left_join(ratios, fc, by = c("gene", "cellType.target"))
}

markers_all <- GetMarkers(sn.all, bulk)
markers_node <- GetMarkers(sn.no.de, bulk)

```

```{r bisque huuki, fig.width = 7, fig.height= 8, echo=FALSE, message=FALSE, warning=FALSE}


# Subset for markers in top 25 rank ratio

markers_all_rank <-  markers_all |>
                      group_by(cellType.target) |>
                      mutate(rank_ratio = row_number()) |>
                      group_by(cellType.target) |>
                      arrange(-rank_ratio, .by_group = T)|>
                      slice_head(n = 25) |>
                      pull(gene)

markers_node_rank <-  markers_node |>
                      group_by(cellType.target) |>
                      mutate(rank_ratio = row_number()) |>
                      group_by(cellType.target) |>
                      arrange(-rank_ratio, .by_group = T)|>
                      slice_head(n = 25) |>
                      pull(gene)



```

```{r bisque all genes, fig.width = 7, fig.height= 8, echo=FALSE, message=FALSE, warning=FALSE}


# Make bulk RNAseq into expression set
# exclude low expressed genes 
bulk_all <- ExpressionSet(assayData = as.matrix(combos.test)) 
bulk_markers_all_rank<- ExpressionSet(assayData = as.matrix(combos.test[markers_all_rank,]))
bulk_markers_node_rank <- ExpressionSet(assayData = as.matrix(combos.test[markers_node_rank,]))

# Run Bisque
RunBisque <- function(bulk.data, seurat.obj){
  
  # Remake seurat as sn.sce without any NA in the idents
sn.sce = seurat.obj |>
          subset(idents = unique(Idents(seurat.obj))[!is.na(unique(Idents(seurat.obj)))]) |>
          as.SingleCellExperiment(assay = "RNA") 

# Create expression set 
exp_set_sce = ExpressionSet(
    assayData = as.matrix(assays(sn.sce)$counts),
    phenoData = AnnotatedDataFrame(
        as.data.frame(colData(sn.sce))[c("ident", "orig.ident", "Participant.ID")]
    )
)

# Check for nuclei w/ zero expression in marker genes
#exp_set_sce <- exp_set_sce[marker_genes, ]
zero_cell_filter <- colSums(exprs(exp_set_sce)) != 0
message("Exclude ", sum(!zero_cell_filter), " cells")
exp_set_sce <- exp_set_sce[, zero_cell_filter]

est_prop = ReferenceBasedDecomposition(
    bulk.eset = bulk.data,
    sc.eset = exp_set_sce,
    cell.types = "ident",
    subject.names = "Participant.ID",
    use.overlap = FALSE
)

est_prop$bulk.props <- t(est_prop$bulk.props)
rm(exp_set_sce)
gc()
#props.bisque <- est_prop$Est.prop.long <- est_prop$bulk.props %>%
#    as.data.frame() %>%
#    tibble::rownames_to_column("Sample") %>%
#    pivot_longer(!Sample, names_to = "cell_type", values_to = "prop")

# Format columns and add meta data for decon method
#colnames(props.bisque) <- c('Sub', 'CellType', 'Prop')
#props.bisque$method <- "bisque"
return(est_prop$bulk.prop)
}


props.bisque.markers.all <- RunBisque(bulk_markers_all_rank, sn.all)
props.bisque.markers.node <- RunBisque(bulk_markers_node_rank, sn.no.de)

```


```{r MuSiC markers node, echo=FALSE, warning=FALSE, include=T}
bulk.es <- exprs(bulk_markers_node_rank)
props.music.markers.node  <- EstimateCellTypeProportions(sn.no.de, bulk.es, for.aitchison = T, sn.individuals = "Participant.ID", marker = markers_node_rank)$Est.prop.weighted 
```

```{r MuSiC markers all, echo=FALSE, warning=FALSE, include=T}
bulk.es <- exprs(bulk_markers_all_rank)
props.music.markers.all  <- EstimateCellTypeProportions(sn.all, bulk.es, for.aitchison = T, sn.individuals = "Participant.ID", marker = markers_all_rank)$Est.prop.weighted 
```

```{r MuSiC all , echo=FALSE, warning=FALSE, include=T}
bulk.es <- exprs(bulk_all)
props.music.all <- EstimateCellTypeProportions(sn.all, bulk.es, for.aitchison = T, sn.individuals = "Participant.ID", marker = rownames(bulk.es))$Est.prop.weighted 
```

```{r merged props, echo=FALSE, warning=FALSE, include=T}

props <- c()

props[["music.all"]] <- props.music.all
props[["music.markers.all"]] <- props.music.markers.all
props[["music.markers.node"]] <- props.music.markers.node
props[["bisque.markers.all"]] <- props.bisque.markers.all
props[["bisque.markers.node"]] <- props.bisque.markers.node

```

```{r plot aitchison , echo=FALSE, warning=FALSE}
# Format deconvolution df
decon.melt <- rbind(props.music.all, props.music.markers_lf) |>
              rbind(props.music.markers_rr) 

# Type formatting
decon.melt$CellType <- factor(decon.melt$CellType, levels = unique(decon.melt$CellType))
decon.melt$Prop <- as.numeric(decon.melt$Prop)
decon.melt$method <- factor(decon.melt$method, levels = unique(decon.melt$method))

decon.melt$n_samples  <- strsplit(as.character(decon.melt$Sub), "-|") |>
                                                       lapply("[[",1) |>
                                                       unlist()


#write.csv(props.bisque[,c(1:3)],"gtex/results/estimates/bcvs/bisque_07112023")
```

```{r music plot controls, fig.width = 16, fig.height= 18, echo=FALSE, message=FALSE, warning=FALSE}
plotDecon <- function(method.use){decon.melt |>
  subset(method == method.use) |>
  ggplot(aes(x=Sub, y=Prop, fill=CellType))  +
   geom_bar(stat='identity',
           position = "fill",
           width = 0.8,
           color = "black")+
   scale_fill_brewer(name = "Cell Type",
                    palette = "Dark2") +
   facet_wrap(~n_samples, 
             scales = "free_x",
             labeller =  label_wrap_gen(multi_line=FALSE)) +
   ylab("Proportion") +
   theme_minimal() +
   theme( axis.text.x = element_blank(),
         strip.text = element_text(size = 20),
         title = element_text(size = 20),
         legend.text = element_text(size = 18),
         axis.ticks.x = element_blank()) +
   xlab("Samples") +
   ggtitle(method.use)
}
fraction.plots <- lapply(unique(decon.melt$method), function(x){plotDecon(x)})

wrap_plots(fraction.plots, ncol = 1)


```

```{r compositional distance, fig.width = 7, fig.height= 8, echo=FALSE, message=FALSE, warning=FALSE}

library(purrr)
library(dplyr)
library(tidyr)

# Function to make nested lists of proportions of UMI used to make the simulated mixtures
# Assumes equal proportions

calculate_proportions <- function(nested_list) {
  # First, let's flatten the nested list to a data frame where each element is a separate row
  df <- map_df(nested_list, ~map_df(.x, ~data.frame(cell_type = .x), .id = "group"), .id = "super_group")
  
  # Next, let's add a group index
  df <- df %>% group_by(super_group, group) %>% mutate(index = paste(super_group, group, sep = "_"))
  
  # Now let's calculate the proportions
  df <- df %>% count(index, cell_type) %>% mutate(prop = n/sum(n)) %>% select(-n) 
  
  # Spread into wide format
  df_wide <- df %>% spread(cell_type, prop, fill = 0) |>
    as.data.frame()
  row.names(df_wide) <- df_wide$index
  
  return(df_wide)
}

sim.fractions <- calculate_proportions(even.perms)

# add super group info and sort columns to match props order
super.group <- sim.fractions$super_group
# Get the column names of sim.fractions that exist in props$bisque
matching_cols <- intersect(colnames(sim.fractions), colnames(props$music.all))

# Order these columns based on their appearance in props$bisque
order_cols <- match(matching_cols, colnames(props$bisque))

# Sort the matching columns based on the order
sorted_cols <- matching_cols[order(order_cols)]

# Reorder the columns of sim.fractions
sim.fractions <- sim.fractions[, sorted_cols]

sim.fractions$super_group <- super.group 

# make props list

#### Calculate Aitchinson distance

CalculateAitchisonDistance <- function(sim_fractions, ests) {
  
  sim_fractions[sim_fractions == 0] <- 0.0001
  ests <- as.data.frame(ests)
  ests[ests == 0] <- 0.0001
  aitch_vals <- data.frame(sample = rownames(sim_fractions),
                           aitchison = NA,
                           super_group = sim_fractions$super_group)
  keep <- colnames(sim_fractions)[which(colnames(sim_fractions)!="super_group")]

  for(i in rownames(sim_fractions)){
    aitch_vals[which(aitch_vals$sample == i),"aitchison"] <- coda.base::dist(
      rbind(sim_fractions[i, keep], ests[i, ]), 
      method = 'aitchison')[1]
  }

  return(aitch_vals)
}

aitch_vals <- lapply(props, function(i) CalculateAitchisonDistance(sim.fractions, i))
names(aitch_vals) <- names(props)

```


```{r compositional distance, fig.width = 12, fig.height= 7, echo=FALSE, message=FALSE, warning=FALSE}



library(dplyr)

# Bind all data frames in the list together into one data frame
collapsed_df <- bind_rows(aitch_vals, .id = "origin")

# Convert to a factor for ordered plotting
collapsed_df$origin <- reorder(collapsed_df$origin, -collapsed_df$aitchison, FUN = sum)


# Plot
ggplot(collapsed_df, aes(x = super_group, y = aitchison)) +
   geom_boxplot(aes(fill = origin), 
               width = 0.5, color = "black", outlier.shape = NA, alpha = 0.5) +
  geom_point(aes(color = origin),
             position = position_jitterdodge(jitter.width = 0.05, jitter.height = 0, dodge.width = 0.5), size = 2, alpha = 0.5) +
  theme(axis.text.x = element_text(color = "black", size = 15, angle = 30, vjust = 0.6),
        axis.text.y = element_text(color = "black", size = 10),
        axis.ticks.x = element_line(color = "black", size = 1),
        panel.background = element_blank(),
        strip.text = element_text(size = 20),
        title = element_text(size = 20),
        legend.text = element_text(size = 18),
        axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
        axis.line.y = element_line(color="black", size = 0.5)) +
  labs(x = "number of cell types", y = "Aitchison Value", color = "Origin", shape = "method") +
  scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2", guide = F) +
  ggtitle("MuSiC outperforms Bisque in all pseudobulk scenarios", 
          subtitle = "node = no differentially expressed genes between bulk and pseudobulk \nall = start with all genes")


```

```{r comp corr matrix, fig.width = 15, fig.height= 12, echo=FALSE, message=FALSE, warning=FALSE}

comp.corr <- as.data.frame(sim.fractions)
comp.corr <- rbind(comp.corr, comp.corr) |>
              rbind(comp.corr) |>
              rbind(comp.corr) |>
              rbind(comp.corr)
comp.corr$aitchison <- collapsed_df$aitchison 
comp.corr$super_group <- as.numeric(comp.corr$super_group)
comp.corr$origin <- collapsed_df$origin



# GPT method

attr(comp.corr$origin, "scores") <- NULL
# Split the dataframe by 'origin'
split_df <- split(comp.corr, comp.corr$origin)

# Calculate correlations for each subset
correlations <- lapply(split_df, function(df) {
                        sapply(df[ , -which(names(df) %in% c("aitchison", "origin"))], function(x) cor(x, df$aitchison))
})

# Convert the list to a dataframe
correlation_df <- do.call(rbind, correlations)
# Create a heatmap of the standardized residuals
heatmap.2(correlation_df, 
          trace = "none", 
          col = viridis(25),
          main = "Correlation of cell types and number to aitchison values \n (Brighter cells mean that more of that thing hurts deconvolution accuracy)",
          xlab = "Cell Types and n cell types",
          ylab = "method",
          key.title = "Residuals",
          cexRow = 1.2,
          srtCol = 45,
          margins=c(15,12))

                    
```


